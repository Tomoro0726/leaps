{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lJK2v17Pq30"
   },
   "source": [
    "# LEAPS v3.0.0\n",
    "\n",
    "Language model guided Exploration of Augmented Protein Sequence space.\n",
    "\n",
    "For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [GitHub](https://github.com/igem-tsukuba/leaps.git).\n",
    "\n",
    "Author: [Yushin Ito](https://github.com/yushin-ito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76BToExOhbPk"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "import os\n",
    "\n",
    "if not os.path.isfile(\"finished_install\"):\n",
    "    # install leaps\n",
    "    os.system(\"git clone https://github.com/igem-tsukuba/leaps.git\")\n",
    "    os.system(\"uv sync --project leaps\")\n",
    "    os.makedirs(\"leaps/bin\", exist_ok=True)\n",
    "\n",
    "    # install plmc\n",
    "    os.system(\"git clone https://github.com/debbiemarkslab/plmc.git\")\n",
    "    os.system(\"make -C plmc all-openmp\")\n",
    "    os.system(\"cp plmc/bin/plmc leaps/bin/\")\n",
    "\n",
    "    # install foldseek\n",
    "    os.system(\"wget https://mmseqs.com/foldseek/foldseek-linux-gpu.tar.gz\")\n",
    "    os.system(\"tar xvfz foldseek-linux-gpu.tar.gz\")\n",
    "    os.system(\"cp foldseek/bin/foldseek leaps/bin/\")\n",
    "\n",
    "    os.chdir(\"leaps\")\n",
    "\n",
    "    os.system(\"touch finished_install\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "rYeAoygbWbMa"
   },
   "outputs": [],
   "source": [
    "# @title Upload CSV file\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "manual = False  # @param {type:\"boolean\"}\n",
    "\n",
    "if manual:\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    src = next(iter(uploaded))\n",
    "    dst = Path(\"data\") / \"input.csv\"\n",
    "\n",
    "    shutil.copy2(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwaD7ylfrpu5"
   },
   "outputs": [],
   "source": [
    "# @title Advanced settings\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = {}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Global\n",
    "project = \"gfp\"  # @param {type:\"string\"}\n",
    "debug = True  # @param {type:\"boolean\"}\n",
    "device = \"cuda\"  # @param [\"cuda\",\"cpu\"]\n",
    "seed = 42  # @param {type:\"integer\"}\n",
    "\n",
    "config = {\n",
    "    \"project\": project,\n",
    "    \"debug\": debug,\n",
    "    \"device\": device,\n",
    "    \"seed\": seed,\n",
    "}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Sampler\n",
    "num_shuffles = 100000  # @param {type:\"integer\"}\n",
    "shuffle_rate = 0.04  # @param {type:\"number\"}\n",
    "window_sizes = [1, 3, 5]  # @param {type:\"raw\"}\n",
    "\n",
    "config[\"sampler\"] = {\n",
    "    \"num_shuffles\": num_shuffles,\n",
    "    \"shuffle_rate\": shuffle_rate,\n",
    "    \"window_sizes\": window_sizes,\n",
    "}\n",
    "\n",
    "config[\"predictor\"] = {}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Predictor (Value1)\n",
    "name = \"ex\"  # @param {type:\"string\"}\n",
    "batch_size = 16  # @param {type:\"integer\"}\n",
    "destruct_per_samples = 0  # @param {type:\"integer\"}\n",
    "model_name_or_path = \"facebook/esm2_t30_150M_UR50D\"  # @param {type:\"string\"}\n",
    "mutate_per_samples = 150  # @param {type:\"integer\"}\n",
    "noise_ratio = 0.1  # @param {type:\"number\"}\n",
    "num_destructions = 2  # @param {type:\"integer\"}\n",
    "num_epochs = 200  # @param {type:\"integer\"}\n",
    "num_mutations = 2  # @param {type:\"integer\"}\n",
    "num_trials = 30  # @param {type:\"integer\"}\n",
    "patience = 20  # @param {type:\"integer\"}\n",
    "test_size = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "if name:\n",
    "    config[\"predictor\"][name] = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"destruct_per_samples\": destruct_per_samples,\n",
    "        \"model_name_or_path\": model_name_or_path,\n",
    "        \"mutate_per_samples\": mutate_per_samples,\n",
    "        \"noise_ratio\": noise_ratio,\n",
    "        \"num_destructions\": num_destructions,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"num_mutations\": num_mutations,\n",
    "        \"num_trials\": num_trials,\n",
    "        \"patience\": patience,\n",
    "        \"test_size\": test_size,\n",
    "    }\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Predictor (Value2)\n",
    "name = \"em\"  # @param {type:\"string\"}\n",
    "batch_size = 16  # @param {type:\"integer\"}\n",
    "destruct_per_samples = 0  # @param {type:\"integer\"}\n",
    "model_name_or_path = \"facebook/esm2_t30_150M_UR50D\"  # @param {type:\"string\"}\n",
    "mutate_per_samples = 150  # @param {type:\"integer\"}\n",
    "noise_ratio = 0.1  # @param {type:\"number\"}\n",
    "num_destructions = 2  # @param {type:\"integer\"}\n",
    "num_epochs = 200  # @param {type:\"integer\"}\n",
    "num_mutations = 2  # @param {type:\"integer\"}\n",
    "num_trials = 30  # @param {type:\"integer\"}\n",
    "patience = 20  # @param {type:\"integer\"}\n",
    "test_size = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "if name:\n",
    "    config[\"predictor\"][name] = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"destruct_per_samples\": destruct_per_samples,\n",
    "        \"model_name_or_path\": model_name_or_path,\n",
    "        \"mutate_per_samples\": mutate_per_samples,\n",
    "        \"noise_ratio\": noise_ratio,\n",
    "        \"num_destructions\": num_destructions,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"num_mutations\": num_mutations,\n",
    "        \"num_trials\": num_trials,\n",
    "        \"patience\": patience,\n",
    "        \"test_size\": test_size,\n",
    "    }\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Predictor (Value3)\n",
    "name = \"brightness\"  # @param {type:\"string\"}\n",
    "batch_size = 16  # @param {type:\"integer\"}\n",
    "destruct_per_samples = 0  # @param {type:\"integer\"}\n",
    "model_name_or_path = \"facebook/esm2_t30_150M_UR50D\"  # @param {type:\"string\"}\n",
    "mutate_per_samples = 150  # @param {type:\"integer\"}\n",
    "noise_ratio = 0.1  # @param {type:\"number\"}\n",
    "num_destructions = 2  # @param {type:\"integer\"}\n",
    "num_epochs = 200  # @param {type:\"integer\"}\n",
    "num_mutations = 2  # @param {type:\"integer\"}\n",
    "num_trials = 30  # @param {type:\"integer\"}\n",
    "patience = 20  # @param {type:\"integer\"}\n",
    "test_size = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "if name:\n",
    "    config[\"predictor\"][name] = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"destruct_per_samples\": destruct_per_samples,\n",
    "        \"model_name_or_path\": model_name_or_path,\n",
    "        \"mutate_per_samples\": mutate_per_samples,\n",
    "        \"noise_ratio\": noise_ratio,\n",
    "        \"num_destructions\": num_destructions,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"num_mutations\": num_mutations,\n",
    "        \"num_trials\": num_trials,\n",
    "        \"patience\": patience,\n",
    "        \"test_size\": test_size,\n",
    "    }\n",
    "\n",
    "config[\"evaluator\"] = {}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Evaluator (Hamiltonian)\n",
    "threshold = -5.0  # @param {type:\"number\"}\n",
    "config[\"evaluator\"][\"hamiltonian\"] = {\"threshold\": threshold}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Evaluator (Likelihoood)\n",
    "batch_size = 32  # @param {type:\"integer\"}\n",
    "model_name_or_path = \"westlake-repl/SaProt_650M_AF2\"  # @param {type:\"string\"}\n",
    "threshold = 0.0  # @param {type:\"number\"}\n",
    "\n",
    "config[\"evaluator\"][\"likelihood\"] = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"model_name_or_path\": model_name_or_path,\n",
    "    \"threshold\": threshold,\n",
    "}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Evaluator (Value1)\n",
    "name = \"ex\"  # @param {type:\"string\"}\n",
    "batch_size = 32  # @param {type:\"integer\"}\n",
    "mode = \"range\"  # @param [\"range\",\"max\",\"min\"]\n",
    "upper = 388  # @param {type:\"integer\"}\n",
    "lower = 378  # @param {type:\"integer\"}\n",
    "series_top_p = 0.4  # @param {type:\"number\"}\n",
    "parallel_top_p = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "if name:\n",
    "    config[\"evaluator\"][name] = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"mode\": mode,\n",
    "        \"upper\": upper,\n",
    "        \"lower\": lower,\n",
    "        \"series\": {\"top_p\": series_top_p},\n",
    "        \"parallel\": {\"top_p\": parallel_top_p},\n",
    "    }\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Evaluator (Value2)\n",
    "name = \"em\"  # @param {type:\"string\"}\n",
    "batch_size = 32  # @param {type:\"integer\"}\n",
    "mode = \"range\"  # @param [\"range\",\"max\",\"min\"]\n",
    "upper = 453  # @param {type:\"integer\"}\n",
    "lower = 443  # @param {type:\"integer\"}\n",
    "series_top_p = 0.4  # @param {type:\"number\"}\n",
    "parallel_top_p = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "if name:\n",
    "    config[\"evaluator\"][name] = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"mode\": mode,\n",
    "        \"upper\": upper,\n",
    "        \"lower\": lower,\n",
    "        \"series\": {\"top_p\": series_top_p},\n",
    "        \"parallel\": {\"top_p\": parallel_top_p},\n",
    "    }\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Evaluator (Value3)\n",
    "name = \"brightness\"  # @param {type:\"string\"}\n",
    "batch_size = 32  # @param {type:\"integer\"}\n",
    "mode = \"max\"  # @param [\"range\",\"max\",\"min\"]\n",
    "series_top_p = 0.4  # @param {type:\"number\"}\n",
    "parallel_top_p = 0.2  # @param {type:\"number\"}\n",
    "\n",
    "if name:\n",
    "    config[\"evaluator\"][name] = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"mode\": mode,\n",
    "        \"series\": {\"top_p\": series_top_p},\n",
    "        \"parallel\": {\"top_p\": parallel_top_p},\n",
    "    }\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Generator\n",
    "batch_size = 32  # @param {type:\"integer\"}\n",
    "max_new_token = 233  # @param {type:\"integer\"}\n",
    "model_name_or_path = \"hugohrban/progen2-small\"  # @param {type:\"string\"}\n",
    "num_epochs = 6  # @param {type:\"integer\"}\n",
    "num_trials = 30  # @param {type:\"integer\"}\n",
    "patience = 3  # @param {type:\"integer\"}\n",
    "prompt = \"MSKGE\"  # @param {type:\"string\"}\n",
    "test_size = 0.1  # @param {type:\"number\"}\n",
    "\n",
    "config[\"generator\"] = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_new_token\": max_new_token,\n",
    "    \"model_name_or_path\": model_name_or_path,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"num_trials\": num_trials,\n",
    "    \"patience\": patience,\n",
    "    \"prompt\": prompt,\n",
    "    \"test_size\": test_size,\n",
    "}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Early Stopper\n",
    "batch_size = 32  # @param {type:\"integer\"}\n",
    "model_name_or_path = \"facebook/esm2_t33_650M_UR50D\"  # @param {type:\"string\"}\n",
    "num_samples = 1000  # @param {type:\"integer\"}\n",
    "patience = 5  # @param {type:\"integer\"}\n",
    "\n",
    "config[\"early_stopper\"] = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"model_name_or_path\": model_name_or_path,\n",
    "    \"num_samples\": num_samples,\n",
    "    \"patience\": patience,\n",
    "}\n",
    "\n",
    "# @markdown <br/>\n",
    "\n",
    "# @markdown ## Runner\n",
    "num_iterations = 35  # @param {type:\"integer\"}\n",
    "num_sequences = 20000  # @param {type:\"integer\"}\n",
    "\n",
    "config[\"runner\"] = {\n",
    "    \"num_iterations\": num_iterations,\n",
    "    \"num_sequences\": num_sequences,\n",
    "}\n",
    "\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.safe_dump(config, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDe_e7IkxeRZ"
   },
   "outputs": [],
   "source": [
    "# @title Run train\n",
    "\n",
    "!uv --project leaps run python -u main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iM0U-SvIkYZV"
   },
   "outputs": [],
   "source": [
    "# @title Download results\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from pydrive2.auth import GoogleAuth\n",
    "from pydrive2.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "project_dir = Path(\"runs\") / config[\"project\"]\n",
    "\n",
    "zip_path = shutil.make_archive(\"result\", \"zip\", root_dir=project_dir, base_dir=\".\")\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "uploaded = drive.CreateFile({\"title\": Path(zip_path).name})\n",
    "uploaded.SetContentFile(zip_path)\n",
    "uploaded.Upload()\n",
    "print(f\"Uploaded file with ID {uploaded.get('id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE0H5NySeUTH"
   },
   "source": [
    "# Instructions <a name=\"Instructions\"></a>\n",
    "\n",
    "## Quick start\n",
    "\n",
    "Press `Runtime`, then `Run all`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
